{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Oscar-Woodward39/Capability-day/blob/main/text_sumarizier_extended_with_output.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers -q"
      ],
      "metadata": {
        "id": "CT-MEcHCfhDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_gjhmg416Jw",
        "outputId": "24bd24b0-8cc1-4cea-ac02-15402f21753d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'summary_text': 'Lack of transparency and reporting standards in the scientifc community has led to increasing and widespread concerns relating to reproduction and integrity of results. metabolomics is highly vulnerable to irreproducibility.'}]\n",
            "Lack of transparency and reporting standards in the scientifc community has led to increasing and widespread concerns relating to reproduction and integrity of results. metabolomics is highly vulnerable to irreproducibility.\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "summary_pipeline = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "article = '''\n",
        "A lack of transparency and reporting standards in the scientifc community has led to increasing and widespread\n",
        "concerns relating to reproduction and integrity of results. As an omics science, which generates vast amounts of data and\n",
        "relies heavily on data science for deriving biological meaning, metabolomics is highly vulnerable to irreproducibility. The\n",
        "metabolomics community has made substantial eforts to align with FAIR data standards by promoting open data formats,\n",
        "data repositories, online spectral libraries, and metabolite databases. Open data analysis platforms also exist; however,\n",
        "they tend to be infexible and rely on the user to adequately report their methods and results. To enable FAIR data science\n",
        "in metabolomics, methods and results need to be transparently disseminated in a manner that is rapid, reusable, and fully\n",
        "integrated with the published work. To ensure broad use within the community such a framework also needs to be inclusive\n",
        "and intuitive for both computational novices and experts alike\n",
        "'''\n",
        "summary = summary_pipeline(article, max_length = 50, min_length= 20)\n",
        "print(summary)\n",
        "text = summary[0]['summary_text']\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "def summarise(article):\n",
        "  summary_pipeline = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "  summary = summary_pipeline(article, max_length = 50, min_length= 20)\n",
        "  text = summary[0]['summary_text']\n",
        "  return text\n"
      ],
      "metadata": {
        "id": "LQajbB93giuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "some_text = '''\n",
        "A lack of transparency and reporting standards in the scientifc community has led to increasing and widespread\n",
        "concerns relating to reproduction\n",
        "'''\n",
        "\n",
        "print(summarise(some_text))"
      ],
      "metadata": {
        "id": "qB3Tck54g-5E",
        "outputId": "879a9b27-e651-44e7-9d66-4000eb8aeee8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 50, but your input_length is only 31. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A lack of transparency and reporting standards in the scientifc community has led to increasing and widespread concerns relating to reproduction.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(str.split)"
      ],
      "metadata": {
        "id": "7pyqFWiQjIpO",
        "outputId": "b8f28b97-7745-4fc3-d30b-d9672e724b54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on method_descriptor:\n",
            "\n",
            "split(self, /, sep=None, maxsplit=-1)\n",
            "    Return a list of the substrings in the string, using sep as the separator string.\n",
            "    \n",
            "      sep\n",
            "        The separator used to split the string.\n",
            "    \n",
            "        When set to None (the default value), will split on any whitespace\n",
            "        character (including \\\\n \\\\r \\\\t \\\\f and spaces) and will discard\n",
            "        empty strings from the result.\n",
            "      maxsplit\n",
            "        Maximum number of splits (starting from the left).\n",
            "        -1 (the default value) means no limit.\n",
            "    \n",
            "    Note, str.split() is mainly useful for data that has been intentionally\n",
            "    delimited.  With natural text that includes punctuation, consider using\n",
            "    the regular expression module.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "some_text = '''\n",
        "A lack of transparency and reporting standards in the scientifc community has led to increasing and widespread\n",
        "concerns relating to reproduction\n",
        "'''\n",
        "count = len(some_text.split())\n",
        "print(count)"
      ],
      "metadata": {
        "id": "T3BcaeAkjyVJ",
        "outputId": "18cc7f19-5f4a-41b7-a38d-6518d34950ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "def summarise(article):\n",
        "  assert len(article.split()) > 50, 'Please make sure your text has at least 50 words'\n",
        "\n",
        "  summary_pipeline = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "  summary = summary_pipeline(article, max_length = 50, min_length= 20)\n",
        "  text = summary[0]['summary_text']\n",
        "  return text"
      ],
      "metadata": {
        "id": "ac9uWyG-ksjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "some_text = '''\n",
        "A lack of transparency and reporting standards in the scientifc community has led to increasing and widespread\n",
        "concerns relating to reproduction\n",
        "'''\n",
        "\n",
        "print(summarise(some_text))"
      ],
      "metadata": {
        "id": "sxHTLUMWltqS",
        "outputId": "f3cc843d-e64d-4055-8abd-20559eb6675a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Please make sure your text has at least 50 words",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-d012a45f13cc>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m '''\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummarise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msome_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-169463c136a5>\u001b[0m in \u001b[0;36msummarise\u001b[0;34m(article)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msummarise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Please make sure your text has at least 50 words'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0msummary_pipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"summarization\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"facebook/bart-large-cnn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Please make sure your text has at least 50 words"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bigger_text='''\n",
        "A lack of transparency and reporting standards in the scientifc community has led to increasing and widespread\n",
        "concerns relating to reproduction and integrity of results. As an omics science, which generates vast amounts of data and\n",
        "relies heavily on data science for deriving biological meaning, metabolomics is highly vulnerable to irreproducibility. The\n",
        "metabolomics community has made substantial eforts to align with FAIR data standards by promoting open data formats,\n",
        "data repositories, online spectral libraries, and metabolite databases.\n",
        "'''\n",
        "\n",
        "print(summarise(bigger_text))"
      ],
      "metadata": {
        "id": "Koub-Hmel-68",
        "outputId": "408797b7-ed89-4a47-919f-0c2fb243a186",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metabolomics generates vast amounts of data andrelies heavily on data science for deriving biological meaning. Metabolomics community has made substantial eforts to align with FAIR data standards by promoting open data formats.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://link.springer.com/content/pdf/10.1007/s11306-019-1588-0.pdf\n",
        "!pip install PyMuPDF -q"
      ],
      "metadata": {
        "id": "VG6EaaMjndO4",
        "outputId": "101c8706-4d47-4876-b9ff-47719c8f6f48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-07 02:50:40--  https://link.springer.com/content/pdf/10.1007/s11306-019-1588-0.pdf\n",
            "Resolving link.springer.com (link.springer.com)... 151.101.0.95, 151.101.64.95, 151.101.128.95, ...\n",
            "Connecting to link.springer.com (link.springer.com)|151.101.0.95|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://idp.springer.com/authorize?response_type=cookie&client_id=springerlink&redirect_uri=https%3A%2F%2Flink.springer.com%2Fcontent%2Fpdf%2F10.1007%2Fs11306-019-1588-0.pdf [following]\n",
            "--2024-03-07 02:50:41--  https://idp.springer.com/authorize?response_type=cookie&client_id=springerlink&redirect_uri=https%3A%2F%2Flink.springer.com%2Fcontent%2Fpdf%2F10.1007%2Fs11306-019-1588-0.pdf\n",
            "Resolving idp.springer.com (idp.springer.com)... 151.101.0.95, 151.101.64.95, 151.101.128.95, ...\n",
            "Connecting to idp.springer.com (idp.springer.com)|151.101.0.95|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://link.springer.com/content/pdf/10.1007/s11306-019-1588-0.pdf [following]\n",
            "--2024-03-07 02:50:41--  https://link.springer.com/content/pdf/10.1007/s11306-019-1588-0.pdf\n",
            "Connecting to link.springer.com (link.springer.com)|151.101.0.95|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1618179 (1.5M) [application/pdf]\n",
            "Saving to: ‘s11306-019-1588-0.pdf.2’\n",
            "\n",
            "s11306-019-1588-0.p 100%[===================>]   1.54M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2024-03-07 02:50:42 (23.3 MB/s) - ‘s11306-019-1588-0.pdf.2’ saved [1618179/1618179]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_A434v6AdI9I",
        "outputId": "094c5cff-2e6c-41cf-aee5-a65a77cb1554",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Toward collaborative open data science in metabolomics using Jupyter Notebooks and cloud computing. A lack of transparency and reporting standards in the scientific community has led to increasing and widespread concerns relating to reproduction and integrity of results.\n",
            "Metabolomics and other post-genomic platforms are a consequence of their success. Advances in measurement technologies continue to gener- ate ever increasing volumes of high-throughput data. For science to move forward under this deluge of\n",
            "Toward collaborative open data science in metabolomics using Jupyter Notebooks and cloud. In an informal context, they can provide a polished ‘showcase’ that allows users to interact with and understand the functionality of\n",
            "Despite the many strengths of open-source GUI work- flows such as Galaxy, they do not always provide users with a free choice of available data analysis methods. For example, unless the user has administrative rights on the server, the browser\n",
            "Even with a free choice of tools and algorithms, work- flows implemented in tools like Galaxy are ‘lin- ear’ in the sense that data passes through a sequential chain of opera- tions. Incurious application of standard\n",
            "Jupyter Notebooks allows seamless integration of code, narrative text, and fig- ures into a single live executable and editable document. Notebooks may be written in a single programming language, or a combina- tion\n",
            "Toward collaborative open data science in metabolomics using Jupyter Notebooks and cloud. Experiential learning tutorials using an example interactive metabolomics data analysis workflow.\n",
            "All code embedded in each of the example notebooks is written in the Python programming language. Digital object identifiers (DOI) are widely used to iden- tify academic and government information in the form of journal articles, research reports and\n",
            "Toward collaborative open data science in metabolomics using Jupyter Notebooks and cloud. This tutorial demonstrates the use of computational note- books for transparent dissemination of data analysis work- flows and results. The workflow is designed to\n",
            "GastricCancer_NMR.xlsx using the Tidy Data framework (Wickham 2014) The data are split into two linked tables. The Excel file can also be downloaded from the Binder virtual machine for\n",
            "Toward collaborative open data science in metabolomics using Jupyter Notebooks and cloud.\n",
            "Anaconda Navigator application provides an interface for creating and managing virtual environments. To create a new virtual environment for the tutorial we will use a configuration file called “environment.yml” that is part of the GitHub rep\n",
            "Tutorial 4 is available in a GitHub repository at https :// githu b.com/cimcb /Metab Simpl eQcVi z. Download and unzip the repository to a folder on your own computer.\n",
            "GitHub imposes version control as a form of best prac- tice on the repositories it hosts. We need to add the new Jupyter notebook and the Excel data file from tutorial 4 to the repository. The final\n",
            "Jupyter Notebooks are an open-source, interactive web tool for creating seamless integration of text, code, and outputs (tables, figures) These computational notebooks can greatly enhance transparent dissemination of data science meth- ods\n",
            "MetaboLights is an open-access general-purpose repository for metabolomics studies and associated meta-data.\n"
          ]
        }
      ],
      "source": [
        "import fitz\n",
        "pdf = \"s11306-019-1588-0.pdf\"\n",
        "doc = fitz.open(pdf)\n",
        "for page in doc:\n",
        "  article = page.get_text(\"Text\")\n",
        "  article = ' '.join(article.split()[:400])\n",
        "  text = summarise(article)\n",
        "  print(text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz\n",
        "def sumarise_pdf(pdf):\n",
        "  doc = fitz.open(pdf)\n",
        "  for page in doc:\n",
        "    article = page.get_text(\"Text\")\n",
        "    article = ' '.join(article.split()[:400])\n",
        "    text = summarise(article)\n",
        "    return text"
      ],
      "metadata": {
        "id": "CM1fsGQP3P_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from urllib.request import Request, urlopen\n",
        "\n",
        "req = Request(\"https://en.wikipedia.org/wiki/Python_(programming_language)\")\n",
        "html_page = urlopen(req)\n",
        "\n",
        "soup = BeautifulSoup(html_page, features=\"html.parser\")\n",
        "\n",
        "for script in soup([\"script\", \"style\"]):\n",
        "    script.extract()\n",
        "\n",
        "text = soup.get_text()\n",
        "\n",
        "lines =  text.splitlines()\n",
        "\n",
        "lines = [x for x in lines if x]\n",
        "\n",
        "text = ' '.join(lines)\n",
        "text = text.split()\n",
        "text = text[:100]\n",
        "text = ' '.join(text)\n",
        "\n",
        "summarise(text)"
      ],
      "metadata": {
        "id": "vSusobUmm5Tr",
        "outputId": "739c2315-acad-442f-ddc7-5ca45e14af48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Python (programming language) - Wikipedia Jump to content Main menu Main menu move to sidebar hide Navigation Main page ContentsCurrent eventsRandom articleAbout WikipediaContact usDonate Contribute HelpLearn to editCommunity portalRecent changesUpload file Languages Language'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from urllib.request import Request, urlopen\n",
        "\n",
        "def summarise_webpage(URL):\n",
        "  req = Request(URL)\n",
        "  html_page = urlopen(req)\n",
        "  soup = BeautifulSoup(html_page, features=\"html.parser\")\n",
        "\n",
        "  for script in soup([\"script\", \"style\"]):\n",
        "      script.extract()\n",
        "\n",
        "  text = soup.get_text()\n",
        "  lines =  text.splitlines()\n",
        "  lines = [x for x in lines if x]\n",
        "  text = ' '.join(lines)\n",
        "  text = text.split()\n",
        "  text = text[:100]\n",
        "  text = ' '.join(text)\n",
        "\n",
        "  return summarise(text)\n",
        "\n",
        "text = summarise_webpage(\"https://en.wikipedia.org/wiki/Python_(programming_language)\")\n",
        "print(text)"
      ],
      "metadata": {
        "id": "PFMntyUDs3dI",
        "outputId": "9d6e8441-2287-41a4-a99e-f4731a983fe6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python (programming language) - Wikipedia Jump to content Main menu Main menu move to sidebar hide Navigation Main page ContentsCurrent eventsRandom articleAbout WikipediaContact usDonate Contribute HelpLearn to editCommunity portalRecent changesUpload file Languages Language\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers -q\n",
        "!pip install PyMuPDF -q\n",
        "!wget https://link.springer.com/content/pdf/10.1007/s11306-019-1588-0.pdf"
      ],
      "metadata": {
        "id": "kOqByVidQSOk",
        "outputId": "bc839197-d568-4203-be01-250dc2ada750",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-07 02:57:42--  https://link.springer.com/content/pdf/10.1007/s11306-019-1588-0.pdf\n",
            "Resolving link.springer.com (link.springer.com)... 151.101.0.95, 151.101.64.95, 151.101.128.95, ...\n",
            "Connecting to link.springer.com (link.springer.com)|151.101.0.95|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://idp.springer.com/authorize?response_type=cookie&client_id=springerlink&redirect_uri=https%3A%2F%2Flink.springer.com%2Fcontent%2Fpdf%2F10.1007%2Fs11306-019-1588-0.pdf [following]\n",
            "--2024-03-07 02:57:42--  https://idp.springer.com/authorize?response_type=cookie&client_id=springerlink&redirect_uri=https%3A%2F%2Flink.springer.com%2Fcontent%2Fpdf%2F10.1007%2Fs11306-019-1588-0.pdf\n",
            "Resolving idp.springer.com (idp.springer.com)... 151.101.0.95, 151.101.64.95, 151.101.128.95, ...\n",
            "Connecting to idp.springer.com (idp.springer.com)|151.101.0.95|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://link.springer.com/content/pdf/10.1007/s11306-019-1588-0.pdf [following]\n",
            "--2024-03-07 02:57:43--  https://link.springer.com/content/pdf/10.1007/s11306-019-1588-0.pdf\n",
            "Connecting to link.springer.com (link.springer.com)|151.101.0.95|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1618179 (1.5M) [application/pdf]\n",
            "Saving to: ‘s11306-019-1588-0.pdf.3’\n",
            "\n",
            "s11306-019-1588-0.p 100%[===================>]   1.54M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2024-03-07 02:57:43 (23.0 MB/s) - ‘s11306-019-1588-0.pdf.3’ saved [1618179/1618179]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from urllib.request import Request, urlopen\n",
        "from transformers import pipeline\n",
        "import fitz\n",
        "\n",
        "def summarise(article):\n",
        "  assert len(article.split()) > 50, 'Please make sure your text has at least 50 words'\n",
        "\n",
        "  summary_pipeline = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "  summary = summary_pipeline(article, max_length = 50, min_length= 20)\n",
        "  text = summary[0]['summary_text']\n",
        "  return text\n",
        "\n",
        "def sumarise_pdf(pdf):\n",
        "  doc = fitz.open(pdf)\n",
        "  for page in doc:\n",
        "    article = page.get_text(\"Text\")\n",
        "    article = ' '.join(article.split()[:400])\n",
        "    text = summarise(article)\n",
        "    return text\n",
        "\n",
        "def summarise_webpage(URL):\n",
        "  req = Request(URL)\n",
        "  html_page = urlopen(req)\n",
        "  soup = BeautifulSoup(html_page, features=\"html.parser\")\n",
        "\n",
        "  for script in soup([\"script\", \"style\"]):\n",
        "      script.extract()\n",
        "\n",
        "  text = soup.get_text()\n",
        "  text =  text.splitlines()\n",
        "  text = [x for x in text if x]\n",
        "  text = ' '.join(lines)\n",
        "  text = text.split()\n",
        "  text = text[:100]\n",
        "  text = ' '.join(text)\n",
        "  return summarise(text)\n",
        "\n",
        "\n",
        "print(\"PDF Summary\")\n",
        "print(sumarise_pdf(\"s11306-019-1588-0.pdf\"))\n",
        "\n",
        "print(\"Webiste Summary\")\n",
        "print(summarise_webpage(\"https://en.wikipedia.org/wiki/Python_(programming_language)\"))"
      ],
      "metadata": {
        "id": "B_qn9Qq-3oqs",
        "outputId": "f8ed35cc-8dfd-4ca0-c4ef-24ff1ec8fd4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF Summary\n",
            "Toward collaborative open data science in metabolomics using Jupyter Notebooks and cloud computing. A lack of transparency and reporting standards in the scientific community has led to increasing and widespread concerns relating to reproduction and integrity of results.\n",
            "Webiste Summary\n",
            "Python (programming language) - Wikipedia Jump to content Main menu Main menu move to sidebar hide Navigation Main page ContentsCurrent eventsRandom articleAbout WikipediaContact usDonate Contribute HelpLearn to editCommunity portalRecent changesUpload file Languages Language\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}